{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import config\n",
    "from model import UNet\n",
    "#import config\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destaster_vision_dataset = dataset.DestasterVisionDataset(\n",
    "\t\timage_folder='train/images',\n",
    "\t\ttarget_folder='train/new_targets',\n",
    "\t\tlabels_folder='train/labels',\n",
    "\t\ttransforms=transforms\n",
    "\t)\n",
    "\n",
    "destaster_vision_testset = dataset.DestasterVisionDataset(\n",
    "    image_folder='test/images',\n",
    "    target_folder='test/new_targets',\n",
    "    labels_folder='test/labels',\n",
    "    transforms= transforms\n",
    ")\n",
    "\n",
    "# load the image and mask filepaths in a sorted manner\n",
    "imagePaths = destaster_vision_dataset.images_paths_pre\n",
    "targetPaths = destaster_vision_dataset.target_paths_pre\n",
    "\n",
    "trainloader = DataLoader(destaster_vision_dataset, shuffle=True,\n",
    "    batch_size= config.BATCH_SIZE, pin_memory=False,\n",
    "    num_workers=os.cpu_count())\n",
    "\n",
    "testloader = DataLoader(destaster_vision_testset, shuffle=True,\n",
    "    batch_size= config.BATCH_SIZE, pin_memory=False,\n",
    "    num_workers=os.cpu_count())\n",
    "\n",
    "# initialize our UNet model\n",
    "unet = UNet().to('cpu')\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "optimizer = Adam(unet.parameters(), lr=config.INIT_LR)\n",
    "\n",
    "#calculate needed training steps\n",
    "trainSteps = destaster_vision_dataset.__len__() // config.BATCH_SIZE\n",
    "testSteps = destaster_vision_testset.__len__() // config.BATCH_SIZE\n",
    "\n",
    "#create empt dict to store history\n",
    "history = {'train_loss': [], 'test_loss': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over epochs\n",
    "print(\"[INFO] starting training\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(config.NUM_EPOCHS)):\n",
    "\tprint('epoch started')\n",
    "\t# set the model in training mode\n",
    "\tunet.train()\n",
    "\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalTestLoss = 0\n",
    "\n",
    "\t# loop over the training set\n",
    "\tfor (i, (x, y)) in enumerate(trainloader):\n",
    "\t\tprint('ping')\n",
    "\t\t'''\n",
    "\t\t#load images\n",
    "\t\tx = cv2.imread(x[i])\n",
    "\t\ty = cv2.imread(y[i])\n",
    "\n",
    "\t\t#turn images to tensor\n",
    "\t\tx = transforms(x)\n",
    "\t\ty = transforms(y)\n",
    "\t\t'''\n",
    "\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = unet(x)\n",
    "\t\tloss = lossFunc(pred, y)\n",
    "\t\t# first, zero out any previously accumulated gradients, then\n",
    "\t\t# perform backpropagation, and then update model parameters\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t# add the loss to the total training loss so far\n",
    "\t\ttotalTrainLoss += loss\n",
    "\n",
    "\n",
    "\t# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tunet.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in testloader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = unet(x)\n",
    "\t\t\ttotalTestLoss += lossFunc(pred, y)\n",
    "\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgTestLoss = totalTestLoss / testSteps\n",
    "\t# update our training history\n",
    "\thistory[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\thistory[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.NUM_EPOCHS))\n",
    "\tprint(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, avgTestLoss))\n",
    "\n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(history[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(history[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(config.PLOT_PATH)\n",
    "# serialize the model to disk\n",
    "torch.save(unet, config.MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
